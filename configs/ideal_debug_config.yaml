csil:
  max_reward: 6.215108223463887
  min_var: 1.0e-05
  refine_reward: true
  reward_kl_scale_factor: 1
  reward_learning_rate: 0.001
  reward_refinement_steps: -1
  reward_scale_factor: 0.5
  reward_grad_norm_clip_threshold: -1
  scale_log_ratios_by_alpha: true
  stationary_activation_function_str: per_relu
networks:
  nr_hidden_units: 1024
  bottleneck_size: 48
  negative_reward: true
  layer_norm_policy: true
evaluation:
  start_with_evaluation: true
  record_before_after: false
  record_eval_episodes: true
  num_eval_episodes: 25
  eval_frequency: 50000
  num_final_evaluation_episodes: 50
  plot_actions: false
  num_recordings_per_eval: 5
algorithm:
  anneal_learning_rate: false
  batch_size: 256
  buffer_size: 1000000
  concat_joint_state: false
  concat_object_state: false
  critic_and_reward_utd: 1
  critic_grad_norm_scaling: 1
  critic_learning_rate: 0.0003
  critic_reset_interval: -1
  critic_warmup_steps: 0
  damping: 1
  embedding_noise_alpha: 250
  entropy_coefficient: 0.1
  gamma: 0.99
  image_based_csil: false
  learning_starts: 10000
  normalize_actions: true
  normalize_observations: false
  policy_learning_rate: 0.0003
  save_training_recordings: false
  tau: 0.005
  total_timesteps: 1000000
  training_recording_frequency: 20
  use_embedding_noise: false
  use_embedding_noise_in_rl: false
  use_linear_residual_combination: false
  use_vla: false
  use_vla_action_for_hetstat: false
sacfd:
  demo_to_online_ratio: 0.1
checkpoints:
  checkpoint_dir: null
  max_num_checkpoints: 10
  reload_checkpoint: false
  saving_frequency: -1
environment:
  value:
    as_high: [1, 1, 1, 1, 1, 1, 1]
    as_low: [-1, -1, -1, -1, -1, -1, -1]
    env_type: robomimic
    language_instruction: pick coke can
    max_episode_length: 400
    name: NutAssemblySquare
    num_actions: 7
    render_fps: 30
    action_shape: (1, 7)
    obs_shape: (1, 23)
    task_prompt: put ring on stick
general:
  value:
    experiment_name: 'states-only - '
    root_dir_name: 
    save_replay_buffers: false
    seed: 7
    use_double_precision: false
pretraining:
  value:
    critic_learning_rate: 0.001
    critic_pretrain_steps: 2000
    dataset_filename: /home/scherer//robomimic_datasets/square/ph/high_dim_v141.hdf5
    entropy_coefficient_init: 0
    eval_frequency: -1
    num_demonstrations: 100
    policy_learning_rate: 0.0001
    policy_pretrain_steps: 50000
    replay_buffer_evaluation_episodes: 20
    save_checkpoint: false
    target_entropy_factor: 5
    tau: 0.005
    use_parameter_kl_term: false
    vla_noise_stddev: 0.008
vla:
  pizero_config: newer_model_lora
  checkpoint_dir: /home/scherer//checkpoints/pi0_mimicgen_robomimic_ph/balanced_mimicgen_lora/29999
  token_selection: first
